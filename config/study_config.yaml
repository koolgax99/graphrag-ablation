parameters:
  - temperature: [0.0]
  - model: [llama-4-scout]
  - mode: [graph_vector_fulltext, iterative_multihop, graph_of_thought]
